{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#Used for pretty printing\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>homesection</th>\n",
       "      <th>publishdate</th>\n",
       "      <th>pageviews</th>\n",
       "      <th>popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18976</td>\n",
       "      <td>Fem danskere i Touren: Sunweb udtager Søren Kragh</td>\n",
       "      <td>Cykling</td>\n",
       "      <td>2018-07-02 17:41:01 UTC</td>\n",
       "      <td>1499</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31594</td>\n",
       "      <td>Klæstrup gift i moské: Jeg er så lykkelig</td>\n",
       "      <td>Danske kendte</td>\n",
       "      <td>2018-08-13 17:40:39 UTC</td>\n",
       "      <td>227329</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10062</td>\n",
       "      <td>Teenager druknet efter skub i leg: Nu er kamme...</td>\n",
       "      <td>112</td>\n",
       "      <td>2018-06-02 09:57:02 UTC</td>\n",
       "      <td>85556</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23137</td>\n",
       "      <td>It-fejl i europæisk flyveplansystem er rettet</td>\n",
       "      <td>Samfund</td>\n",
       "      <td>2018-04-04 00:10:44 UTC</td>\n",
       "      <td>1346</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7639</td>\n",
       "      <td>Voldtaget to timer på loftet over café: - Jeg ...</td>\n",
       "      <td>112</td>\n",
       "      <td>2018-08-06 20:42:12 UTC</td>\n",
       "      <td>303642</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0       18976  Fem danskere i Touren: Sunweb udtager Søren Kragh   \n",
       "1       31594          Klæstrup gift i moské: Jeg er så lykkelig   \n",
       "2       10062  Teenager druknet efter skub i leg: Nu er kamme...   \n",
       "3       23137      It-fejl i europæisk flyveplansystem er rettet   \n",
       "4        7639  Voldtaget to timer på loftet over café: - Jeg ...   \n",
       "\n",
       "     homesection              publishdate  pageviews  popularity  \n",
       "0        Cykling  2018-07-02 17:41:01 UTC       1499           0  \n",
       "1  Danske kendte  2018-08-13 17:40:39 UTC     227329           1  \n",
       "2            112  2018-06-02 09:57:02 UTC      85556           1  \n",
       "3        Samfund  2018-04-04 00:10:44 UTC       1346           0  \n",
       "4            112  2018-08-06 20:42:12 UTC     303642           1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Data/headlinesViews.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31518, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    15799\n",
       "0    15719\n",
       "Name: popularity, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.popularity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fem danskere i Touren: Sunweb udtager Søren Kragh</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Klæstrup gift i moské: Jeg er så lykkelig</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Teenager druknet efter skub i leg: Nu er kamme...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It-fejl i europæisk flyveplansystem er rettet</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Voldtaget to timer på loftet over café: - Jeg ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  popularity\n",
       "0  Fem danskere i Touren: Sunweb udtager Søren Kragh           0\n",
       "1          Klæstrup gift i moské: Jeg er så lykkelig           1\n",
       "2  Teenager druknet efter skub i leg: Nu er kamme...           1\n",
       "3      It-fejl i europæisk flyveplansystem er rettet           0\n",
       "4  Voldtaget to timer på loftet over café: - Jeg ...           1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop([\"Unnamed: 0\", \"publishdate\",\"homesection\",\"pageviews\"], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fem danskere i touren: sunweb udtager søren kragh</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>klæstrup gift i moské: jeg er så lykkelig</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>teenager druknet efter skub i leg: nu er kamme...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it-fejl i europæisk flyveplansystem er rettet</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>voldtaget to timer på loftet over café: - jeg ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31513</th>\n",
       "      <td>helt til hest: politiet mangler borgernes hjæl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31514</th>\n",
       "      <td>kæmpe ballade under pokalfinale: politiet brug...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31515</th>\n",
       "      <td>lavede sexbånd med kardashian: jeg er videre</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31516</th>\n",
       "      <td>politiet bekræfter: nu skal ronaldo afhøres</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31517</th>\n",
       "      <td>superliga-stjerne: min bror forsvandt og blev ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31518 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  popularity\n",
       "0      fem danskere i touren: sunweb udtager søren kragh           0\n",
       "1              klæstrup gift i moské: jeg er så lykkelig           1\n",
       "2      teenager druknet efter skub i leg: nu er kamme...           1\n",
       "3          it-fejl i europæisk flyveplansystem er rettet           0\n",
       "4      voldtaget to timer på loftet over café: - jeg ...           1\n",
       "...                                                  ...         ...\n",
       "31513  helt til hest: politiet mangler borgernes hjæl...           0\n",
       "31514  kæmpe ballade under pokalfinale: politiet brug...           1\n",
       "31515       lavede sexbånd med kardashian: jeg er videre           0\n",
       "31516       politiet bekræfter: nu skal ronaldo afhøres            1\n",
       "31517  superliga-stjerne: min bror forsvandt og blev ...           1\n",
       "\n",
       "[31518 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make everything lowercase\n",
    "df[\"title\"] = df[\"title\"].str.lower()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     fem danskere i touren sunweb udtager søren kragh\n",
       "1             klæstrup gift i moské jeg er så lykkelig\n",
       "2    teenager druknet efter skub i leg nu er kammer...\n",
       "3         itfejl i europæisk flyveplansystem er rettet\n",
       "4    voldtaget to timer på loftet over café  jeg vi...\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove all punctuation ()\n",
    "df['title'] = df['title'].str.replace('[^\\w\\s]','')\n",
    "df['title'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['og', 'i', 'jeg', 'det', 'at', 'en', 'den', 'til', 'er', 'som', 'på', 'de', 'med', 'han', 'af', 'for', 'ikke', 'der', 'var', 'mig', 'sig', 'men', 'et', 'har', 'om', 'vi', 'min', 'havde', 'ham', 'hun', 'nu', 'over', 'da', 'fra', 'du', 'ud', 'sin', 'dem', 'os', 'op', 'man', 'hans', 'hvor', 'eller', 'hvad', 'skal', 'selv', 'her', 'alle', 'vil', 'blev', 'kunne', 'ind', 'når', 'være', 'dog', 'noget', 'ville', 'jo', 'deres', 'efter', 'ned', 'skulle', 'denne', 'end', 'dette', 'mit', 'også', 'under', 'have', 'dig', 'anden', 'hende', 'mine', 'alt', 'meget', 'sit', 'sine', 'vor', 'mod', 'disse', 'hvis', 'din', 'nogle', 'hos', 'blive', 'mange', 'ad', 'bliver', 'hendes', 'været', 'thi', 'jer', 'sådan']\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download('stopwords')\n",
    "stop = stopwords.words('danish')\n",
    "print(stop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fem danskere i touren sunweb udtager søren kragh</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>klæstrup gift i moské jeg er så lykkelig</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>teenager druknet efter skub i leg nu er kammer...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>itfejl i europæisk flyveplansystem er rettet</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>voldtaget to timer på loftet over café  jeg vi...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  stopwords\n",
       "0   fem danskere i touren sunweb udtager søren kragh          1\n",
       "1           klæstrup gift i moské jeg er så lykkelig          3\n",
       "2  teenager druknet efter skub i leg nu er kammer...          4\n",
       "3       itfejl i europæisk flyveplansystem er rettet          2\n",
       "4  voldtaget to timer på loftet over café  jeg vi...          8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show amount of stop words\n",
    "df['stopwords'] = df['title'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "df[['title','stopwords']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     fem danskere touren sunweb udtager søren kragh\n",
       "1                    klæstrup gift moské så lykkelig\n",
       "2          teenager druknet skub leg kammerat sigtet\n",
       "3            itfejl europæisk flyveplansystem rettet\n",
       "4    voldtaget to timer loftet café straffe fortjent\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove stop words\n",
    "df['title'] = df['title'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "df['title'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dansk      1380\n",
       "kan         973\n",
       "mand        854\n",
       "så          781\n",
       "ny          774\n",
       "får         720\n",
       "ved         618\n",
       "år          612\n",
       "danmark     599\n",
       "danske      595\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the 10 most common words\n",
    "### Should this be all words above X count? Or something else?\n",
    "freq = pd.Series(' '.join(df['title']).split()).value_counts()[:10]\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     fem danskere touren sunweb udtager søren kragh\n",
       "1                       klæstrup gift moské lykkelig\n",
       "2          teenager druknet skub leg kammerat sigtet\n",
       "3            itfejl europæisk flyveplansystem rettet\n",
       "4    voldtaget to timer loftet café straffe fortjent\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the 10 most common words as they're not useful when classifying our data \n",
    "# (This allows us to catch some additional \"stop words\" not in our stop word library)\n",
    "freq = list(freq.index)\n",
    "df['title'] = df['title'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "df['title'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "heksejægere     1\n",
       "cremet          1\n",
       "mæglerbrøler    1\n",
       "relativt        1\n",
       "finalestart     1\n",
       "rippet          1\n",
       "betonblok       1\n",
       "geislers        1\n",
       "majkens         1\n",
       "købsprisen      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the 10 least common words\n",
    "### Should this be all words that are counted only once? Or something else?\n",
    "\n",
    "freq = pd.Series(' '.join(df['title']).split()).value_counts()[-10:]\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     fem danskere touren sunweb udtager søren kragh\n",
       "1                       klæstrup gift moské lykkelig\n",
       "2          teenager druknet skub leg kammerat sigtet\n",
       "3            itfejl europæisk flyveplansystem rettet\n",
       "4    voldtaget to timer loftet café straffe fortjent\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the rarest words\n",
    "freq = list(freq.index)\n",
    "df['title'] = df['title'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "df['title'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23638,), (7880,), (23638,), (7880,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.title, df.popularity, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect_new = TfidfVectorizer(min_df=5).fit(X_train)\n",
    "tfid_x_train = vect_new.transform(X_train)\n",
    "tfid_x_test = vect_new.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'class_weight': None,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'auto',\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 100,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': 42,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state = 42)\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(rf.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': [2, 7, 12, 18, 23, 28, 34, 39, 44, 50],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [1, 50, 100, 150, 200, 250, 300, 350, 400, 450, 500]}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 1, stop = 500, num = 11)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(2, 50, num = 10)]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf\n",
    "              }\n",
    "\n",
    "pprint(random_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                    ccp_alpha=0.0,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features='auto',\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    max_samples=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    n_estimators=100,\n",
       "                                                    n_jobs...\n",
       "                                                    warm_start=False),\n",
       "                   iid='deprecated', n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [2, 7, 12, 18, 23, 28, 34,\n",
       "                                                      39, 44, 50],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [1, 50, 100, 150, 200,\n",
       "                                                         250, 300, 350, 400,\n",
       "                                                         450, 500]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "rf_random.fit(tfid_x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 500,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 4,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 12}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6433287773255773"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6459390862944162"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "base_model = RandomForestClassifier(random_state = 42)\n",
    "base_model.fit(tfid_x_train, y_train)\n",
    "base_pred = base_model.predict(tfid_x_test)\n",
    "base_accuracy = accuracy_score(base_pred, y_test)\n",
    "base_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Tweaked\n",
      "Training set score: 0.683\n",
      "Test set score: 0.647\n"
     ]
    }
   ],
   "source": [
    "best_random = rf_random.best_estimator_\n",
    "best_pred_train = best_random.predict(tfid_x_train)\n",
    "best_pred_test = best_random.predict(tfid_x_test)\n",
    "print(\"Random Forest Tweaked\")\n",
    "print(\"Training set score: {:.3f}\".format(accuracy_score(best_pred_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(accuracy_score(best_pred_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improvement of 0.12%.\n"
     ]
    }
   ],
   "source": [
    "print('Improvement of {:0.2f}%.'.format( 100 * (accuracy_score(best_pred_test, y_test) - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Basically RandomForestClassifier is bad so we won't be using that. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
